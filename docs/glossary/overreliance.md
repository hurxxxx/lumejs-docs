---
title: 과잉 의존 / 자동화 편향(Overreliance / Automation Bias)
---

[← 용어 사전](../glossary)

## 한 줄 정의
과잉 의존(자동화 편향)이란 AI의 출력을 지나치게 신뢰하여 인간 고유의 판단력과 비판적 사고가 약화되는 심리적·조직적 현상이다.

## 왜 중요한가(실무)
AI가 높은 정확도를 보여줄수록 사람은 자연스럽게 AI의 판단을 무비판적으로 수용하게 된다. 처음에는 "참고용"으로 시작했던 AI 추천이 어느새 "사실상 최종 결정"이 되는 일이 흔하다. 이때 AI가 잘못된 결과를 내놓더라도 담당자가 이를 걸러내지 못하는 상황이 발생한다.

의료 진단 보조, 법률 문서 검토, 채용 심사 등 고위험 영역에서 과잉 의존은 심각한 결과를 초래할 수 있다. AI가 놓친 이상 징후를 의사가 재확인하지 않거나, AI가 부적합하다고 판정한 지원자를 인사 담당자가 추가 검토 없이 탈락시키는 사례가 이에 해당한다.

조직 차원에서는 AI 도입 초기부터 "인간이 최종 판단한다"는 원칙을 제도화하고, 주기적으로 AI 결과를 의심하고 검증하는 문화를 만들어야 한다. 기술의 문제가 아니라 사람과 조직의 문제이기 때문이다.

## 핵심 이론(직관)
### 1) 자동화 편향의 심리학적 메커니즘
인간은 인지적 부하를 줄이려는 본능이 있다. AI가 답을 제시하면 뇌는 "이미 해결됨"으로 인식하고 추가 검토에 에너지를 쓰지 않으려 한다. 이를 인지적 절약(cognitive miser) 경향이라 한다. 특히 AI의 과거 성공 경험이 쌓일수록 이 편향은 더욱 강화된다.

### 2) 기술 숙련도의 역설
AI에 의존하는 기간이 길어지면 해당 업무를 직접 수행하는 역량이 퇴화한다. 내비게이션에 익숙해지면 길 찾기 능력이 약해지듯, AI 보조 도구에 익숙해진 실무자는 AI 없이는 판단을 내리기 어려워진다. 이는 AI 시스템 장애 시 업무 마비로 이어질 수 있는 조직적 리스크다.

## 실무 포인트
### 1) 인간 검토(Human-in-the-Loop) 제도화
고위험 의사결정에는 반드시 사람이 최종 승인하는 단계를 설계한다. 단순히 "확인 버튼 클릭"이 아니라, AI의 근거를 검토하고 이의를 제기할 수 있는 구조적 장치가 필요하다. 예를 들어, AI 추천 결과와 함께 판단 근거를 표시하고 담당자가 근거의 타당성을 평가하도록 한다.

### 2) 정기적 역량 유지 훈련
AI 없이 업무를 수행하는 훈련을 주기적으로 실시한다. 분기별로 AI 보조 없이 샘플 케이스를 직접 처리해 보는 "수동 검증일"을 운영하면 실무자의 판단 역량이 퇴화하는 것을 방지할 수 있다.

### 3) AI 오류 사례 공유 문화
AI가 틀린 사례를 팀 내에서 적극 공유하고 학습 자료로 활용한다. "AI도 틀릴 수 있다"는 인식이 조직에 자연스럽게 자리 잡으면 건강한 회의적 태도가 형성된다.

## 체크리스트
- 고위험 의사결정에 인간 최종 검토 단계가 설계되어 있는가?
- AI의 판단 근거(설명 가능성)가 사용자에게 함께 제공되는가?
- 담당자가 AI 결과에 이의를 제기할 수 있는 공식 절차가 있는가?
- AI 없이 업무를 수행하는 역량 유지 훈련이 실시되고 있는가?
- AI 오류 사례를 수집하고 조직 내 공유하는 체계가 있는가?
- AI 의존도가 높아지는 업무 영역을 주기적으로 식별하고 있는가?
