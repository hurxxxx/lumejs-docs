---
title: 추론(Inference)
---

[← 용어 사전](../glossary)

## 한 줄 정의
추론(Inference)은 학습이 완료된 AI 모델에 입력을 넣어 결과를 얻는 과정, 즉 AI가 실제로 "일하는" 단계다.

## 왜 중요한가(실무)
AI 도입의 비용 구조를 이해하려면 학습(Training)과 추론(Inference)을 구분해야 한다.
학습은 모델을 만드는 일회성(또는 저빈도) 투자이고, 추론은 모델을 사용할 때마다 발생하는 운영 비용이다.
대부분의 기업은 이미 학습된 모델(GPT, Claude 등)을 API로 호출하므로, 실질적인 AI 비용 = 추론 비용이다.

추론 비용은 호출 횟수, 입출력 토큰 수, 모델 크기에 비례한다.
따라서 "어떤 업무에 어떤 크기의 모델을 몇 번 호출할 것인가"가 AI 운영 예산의 핵심 변수가 되며, 이를 설계 단계에서 고려하지 않으면 예상치 못한 비용 폭증이 발생할 수 있다.

## 핵심 이론(직관)
### 1) 학습은 '교육', 추론은 '실무 투입'
학습(Training)은 수개월간 대량의 데이터로 모델을 가르치는 과정이고, 추론(Inference)은 교육받은 모델이 실제 질문에 답하는 과정이다.
API를 호출해서 답변을 받는 것, 챗봇이 고객에게 응답하는 것, 문서를 요약하는 것 모두 추론이다.

### 2) 추론 속도 = 사용자 경험
추론에 걸리는 시간(지연 시간, Latency)은 사용자 체감 품질에 직접 영향을 준다.
큰 모델은 정확하지만 느리고, 작은 모델은 빠르지만 품질이 떨어질 수 있다.
실시간 응답이 필요한 서비스(챗봇, 검색)와 배치 처리가 가능한 업무(문서 분석, 보고서 생성)에서 모델 선택 기준이 달라지는 이유다.

## 실무 포인트
### 1) 추론 비용은 '설계'에서 결정된다
같은 업무라도 프롬프트를 어떻게 구성하느냐에 따라 토큰 사용량이 2~5배 차이 난다.
불필요하게 긴 시스템 프롬프트, 매번 전체 문서를 컨텍스트에 넣는 구조, 반복 호출 없이 한 번에 해결할 수 있는 작업을 여러 번 나누는 구조 등이 비용을 키운다.
파이프라인 설계 시 토큰 사용량을 시뮬레이션하고, 월간 예상 비용을 미리 산출해야 한다.

### 2) 모델 라우팅으로 비용을 최적화하라
모든 요청에 최고 성능 모델을 쓸 필요는 없다.
단순 분류·정형 응답은 경량 모델로 처리하고, 복잡한 추론·창작이 필요한 요청만 대형 모델로 보내는 "라우팅" 전략이 비용 대비 성능을 극대화한다.

## 체크리스트
- 주요 업무 시나리오별 평균 입출력 토큰 수를 측정했는가
- 월간 예상 호출 횟수와 비용을 산출했는가
- 실시간 응답이 필요한 업무와 배치 처리 가능한 업무를 구분했는가
- 업무 난이도별 모델 분기(라우팅) 전략을 검토했는가
- 비용 급증 시 알림을 받을 수 있는 모니터링 체계가 있는가
