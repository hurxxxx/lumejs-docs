---
title: 03. AI 리터러시와 안전
---

## 학습 목표
- 환각/편향/오류의 위험을 이해한다.
- 안전한 사용 원칙을 정한다.

## 핵심 개념
- **환각**: 그럴듯하지만 사실이 아닌 결과
- **검증**: 출처 확인, 대조, 샘플 테스트
- **민감정보**: 개인정보/회사기밀/계약정보
- **HITL**: 사람 검토가 필수인 흐름

## 예시
- 정책 문서를 요약할 때는 반드시 원문과 대조한다.

## 실습
1. 내 업무에서 "사람 검토"가 필요한 문서를 분류한다.
2. 금지/주의/허용 항목을 3가지씩 적는다.

## 체크리스트
- [ ] 민감정보를 가명 처리했다
- [ ] 결과 검증 절차를 정의했다
- [ ] 최종 판단은 사람이 한다

## 요약
AI는 초안을 제공하지만 **책임은 사람에게 있다**.

## 참고/출처
- NIST AI RMF 1.0: https://www.nist.gov/publications/artificial-intelligence-risk-management-framework-ai-rmf-10
- NIST AI RMF Generative AI Profile: https://www.nist.gov/publications/artificial-intelligence-risk-management-framework-generative-artificial-intelligence
- ISO/IEC 42001:2023: https://www.iso.org/standard/42001
- EU AI Act Article 4 (AI literacy): https://digital-strategy.ec.europa.eu/en/policies/ai-talent-skills-and-literacy
